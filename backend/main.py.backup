"""
FastAPI backend server for LaunchBox
Provides OpenAI API integration with secure API key management
"""
import json
import asyncio
from typing import Dict, Any
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from services.openai_service import openai_service
from services.mock_openai_service import mock_openai_service
from services.gpt_image_service import gpt_image_service
from services.action_executor_service import action_executor_service
from config import config

# FastAPI app initialization
app = FastAPI(
    title="LaunchBox Backend",
    description="Backend API for LaunchBox with OpenAI integration",
    version="1.0.0"
)

# CORS middleware configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=[config.FRONTEND_URL, "http://localhost:3000"],  # Add any additional origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for request/response
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: list[ChatMessage]
    temperature: float = 0.7
    max_tokens: int = 2000

class ImageGenerationRequest(BaseModel):
    prompt: str
    width: int = 1024
    height: int = 1024

class ActionExecutionRequest(BaseModel):
    action_id: str
    action_name: str
    action_type: str
    parameters: Dict[str, Any]

class ChatResponse(BaseModel):
    success: bool
    content: str = None
    error: str = None
    usage: Dict[str, int] = None

# WebSocket connection manager
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)

    async def send_message(self, websocket: WebSocket, message: dict):
        if websocket in self.active_connections:
            await websocket.send_text(json.dumps(message))

manager = ConnectionManager()

# Health check endpoint
@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "LaunchBox Backend",
        "openai_configured": bool(config.OPENAI_API_KEY)
    }

# Non-streaming chat endpoint
@app.post("/api/chat", response_model=ChatResponse)
async def chat_completion(request: ChatRequest):
    """
    Non-streaming chat completion endpoint
    """
    try:
        # Choose service based on configuration
        service = mock_openai_service if config.USE_MOCK_OPENAI else openai_service
        
        # Format messages for API
        formatted_messages = service.format_messages(
            [msg.dict() for msg in request.messages]
        )
        
        # Get completion from service
        result = await service.get_chat_completion(
            messages=formatted_messages,
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )
        
        if result["success"]:
            return ChatResponse(
                success=True,
                content=result["content"],
                usage=result["usage"]
            )
        else:
            return ChatResponse(
                success=False,
                error=result["error"]
            )
            
    except Exception as e:
        return ChatResponse(
            success=False,
            error=f"Server error: {str(e)}"
        )

# WebSocket endpoint for streaming chat
@app.websocket("/ws/chat")
async def websocket_chat_endpoint(websocket: WebSocket):
    """
    WebSocket endpoint for streaming chat with OpenAI
    """
    await manager.connect(websocket)
    
    try:
        while True:
            # Receive message from client
            data = await websocket.receive_text()
            message_data = json.loads(data)
            
            # Send acknowledgment
            await manager.send_message(websocket, {
                "type": "status",
                "message": "Processing your request..."
            })
            
            # Extract message data
            messages = message_data.get("messages", [])
            temperature = message_data.get("temperature", 0.7)
            max_tokens = message_data.get("max_tokens", 2000)
            
            # Choose service based on configuration
            service = mock_openai_service if config.USE_MOCK_OPENAI else openai_service
            
            # Format messages for API
            formatted_messages = service.format_messages(messages)
            
            # Send start streaming signal
            service_name = "Mock GPT-5" if config.USE_MOCK_OPENAI else f"Compass {config.OPENAI_MODEL}"
            await manager.send_message(websocket, {
                "type": "stream_start",
                "message": f"Starting response from {service_name}..."
            })
            
            # Stream response from service
            full_response = ""
            async for chunk in service.stream_chat_completion(
                messages=formatted_messages,
                temperature=temperature,
                max_tokens=max_tokens
            ):
                full_response += chunk
                
                # Send chunk to client
                await manager.send_message(websocket, {
                    "type": "stream_chunk",
                    "content": chunk
                })
                
                # Small delay to prevent overwhelming the client
                await asyncio.sleep(0.01)
            
            # Send completion signal
            await manager.send_message(websocket, {
                "type": "stream_complete",
                "message": "Response completed",
                "full_response": full_response
            })
            
    except WebSocketDisconnect:
        manager.disconnect(websocket)
        print("Client disconnected from WebSocket")
    except Exception as e:
        await manager.send_message(websocket, {
            "type": "error",
            "message": f"Error: {str(e)}"
        })
        print(f"WebSocket error: {str(e)}")

# Test endpoint to verify OpenAI connection
@app.get("/api/test-openai")
async def test_openai():
    """
    Test endpoint to verify OpenAI API connection
    """
    try:
        test_messages = [
            {"role": "user", "content": "Hello, this is a test message. Please respond briefly."}
        ]
        
        # Choose service based on configuration
        service = mock_openai_service if config.USE_MOCK_OPENAI else openai_service
        result = await service.get_chat_completion(test_messages)
        
        if result["success"]:
            return {
                "status": "success",
                "message": "Compass API connection successful",
                "response": result["content"],
                "usage": result["usage"]
            }
        else:
            return {
                "status": "error",
                "message": "Compass API connection failed",
                "error": result["error"]
            }
            
    except Exception as e:
        return {
            "status": "error",
            "message": "Server error during Compass API test",
            "error": str(e)
        }

@app.post("/api/generate-image")
async def generate_image(request: ImageGenerationRequest):
    """生成图像API端点"""
    try:
        result = await gpt_image_service.generate_image(
            prompt=request.prompt,
            width=request.width,
            height=request.height
        )
        return result
    except Exception as e:
        return {
            "success": False,
            "error": f"图像生成失败: {str(e)}"
        }

@app.post("/api/execute-action")
async def execute_action(request: ActionExecutionRequest):
    """执行Action API端点"""
    try:
        result = await action_executor_service.execute_action(
            action_id=request.action_id,
            action_name=request.action_name,
            action_type=request.action_type,
            parameters=request.parameters
        )
        return result
    except Exception as e:
        return {
            "success": False,
            "error": f"执行Action失败: {str(e)}"
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=config.HOST,
        port=config.PORT,
        reload=config.DEBUG,
        log_level="info"
    )
